{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "from PIL import Image\n",
    "import matplotlib.image as img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to parse the dataset ONLY ONCE - it takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------SETTING UP THE DATA---------------------------------------------------------\n",
    "#----------------------------------Training Data----------------------------------------------------------------\n",
    "\n",
    "#feature vector size\n",
    "X = np.zeros((375000, 2200))\n",
    "#open the url and read from the lines\n",
    "url_name = \"/Users/benjaminadame/downloads/matched_train.txt\"\n",
    "lines = open(url_name).readlines()\n",
    "#get rid of the firt new line character\n",
    "lines.pop(0)\n",
    "#iteration to format the names and the matched pictures\n",
    "for i,line in enumerate(lines):\n",
    "\n",
    "    tokens = line.split(\"\\t\")\n",
    "    tokens[2] = tokens[2].replace(\"\\n\", \"\")\n",
    "    url_name1 = \"/Users/benjaminadame/Downloads/lfw-deepfunneled/\" + tokens[0] + \"/\" + tokens[0] + \"_\" + \"{:04d}\".format(int(tokens[1]))+\".jpg\"\n",
    "    url_name2 = \"/Users/benjaminadame/Downloads/lfw-deepfunneled/\" + tokens[0] + \"/\" + tokens[0] + \"_\" + \"{:04d}\".format(int(tokens[2]))+\".jpg\"\n",
    "    image1 = img.imread(url_name1)\n",
    "    image2 = img.imread(url_name2)\n",
    "    #reshape the images--- one image remains in one column\n",
    "    image1 = image1.reshape(250*250*3,)\n",
    "    image2 = image2.reshape(250*250*3,)\n",
    "\n",
    "    #input images into a feature vector in this case it is X\n",
    "    #0:187500 is accounting for the rows in the feature vector the same can be said for 187500:37500\n",
    "    # i is just the number of columns which represents the number of images that are being used\n",
    "    X[0:187500,i] = image1\n",
    "    X[187500:375000,i] = image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_name_mis = \"/Users/benjaminadame/downloads/mismatched_train.txt\"\n",
    "lines2 = open(url_name_mis).readlines()\n",
    "\n",
    "#iteration to format the names and the mismatched pictures\n",
    "for i,line in enumerate(lines2):\n",
    "\n",
    "    tokens = line.split(\"\\t\")\n",
    "    tokens[2] = tokens[2].replace(\"\\n\", \"\")\n",
    "    url_name1 = \"/Users/benjaminadame/Downloads/lfw-deepfunneled/\" + tokens[0] + \"/\" + tokens[0] + \"_\" + \"{:04d}\".format(int(tokens[1]))+\".jpg\"\n",
    "    url_name2 = \"/Users/benjaminadame/Downloads/lfw-deepfunneled/\" + tokens[2] + \"/\" + tokens[2] + \"_\" + \"{:04d}\".format(int(tokens[3]))+\".jpg\"\n",
    "    image1 = img.imread(url_name1)\n",
    "    image2 = img.imread(url_name2)\n",
    "    #reshape the images--- one image remains in one column\n",
    "    image1 = image1.reshape(250*250*3,)\n",
    "    image2 = image2.reshape(250*250*3,)\n",
    "    #input images into a feature vector in this case it is X\n",
    "    #0:187500 is accounting for the rows in the feature vector the same can be said for 187500:37500\n",
    "    # i is just the number of columns which represents the number of images that are being used\n",
    "    X[0:187500,1100+i] = image1\n",
    "    X[187500:375000,1100+i] = image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the labels for the training set \n",
    "Y = np.zeros((1, 2200))\n",
    "for i in range(1100):\n",
    "    Y[0, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train', X)\n",
    "np.save('Y_train', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------TESTING DATA---------------------------------------------\n",
    "#feature vector size\n",
    "X_test = np.zeros((375000, 1000))\n",
    "#open the url and read from the lines\n",
    "url_name = \"/Users/benjaminadame/downloads/matched_test.txt\"\n",
    "lines = open(url_name).readlines()\n",
    "#get rid of the firt new line character\n",
    "lines.pop(0)\n",
    "#iteration to format the names and the matched pictures\n",
    "for i,line in enumerate(lines):\n",
    "\n",
    "    tokens = line.split(\"\\t\")\n",
    "    tokens[2] = tokens[2].replace(\"\\n\", \"\")\n",
    "    url_name1 = \"/Users/benjaminadame/Downloads/lfw-deepfunneled/\" + tokens[0] + \"/\" + tokens[0] + \"_\" + \"{:04d}\".format(int(tokens[1]))+\".jpg\"\n",
    "    url_name2 = \"/Users/benjaminadame/Downloads/lfw-deepfunneled/\" + tokens[0] + \"/\" + tokens[0] + \"_\" + \"{:04d}\".format(int(tokens[2]))+\".jpg\"\n",
    "    image1 = img.imread(url_name1)\n",
    "    image2 = img.imread(url_name2)\n",
    "    #reshape the images--- one image remains in one column\n",
    "    image1 = image1.reshape(250*250*3,)\n",
    "    image2 = image2.reshape(250*250*3,)\n",
    "\n",
    "    #input images into a feature vector in this case it is X\n",
    "    #0:187500 is accounting for the rows in the feature vector the same can be said for 187500:37500\n",
    "    # i is just the number of columns which represents the number of images that are being used\n",
    "    X_test[0:187500,i] = image1\n",
    "    X_test[187500:375000,i] = image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_name_mis = \"/Users/benjaminadame/downloads/mismatched_test.txt\"\n",
    "lines2 = open(url_name_mis).readlines()\n",
    "\n",
    "#iteration to format the names and the mismatched pictures\n",
    "for i,line in enumerate(lines2):\n",
    "\n",
    "    tokens = line.split(\"\\t\")\n",
    "    tokens[2] = tokens[2].replace(\"\\n\", \"\")\n",
    "    url_name1 = \"/Users/benjaminadame/Downloads/lfw-deepfunneled/\" + tokens[0] + \"/\" + tokens[0] + \"_\" + \"{:04d}\".format(int(tokens[1]))+\".jpg\"\n",
    "    url_name2 = \"/Users/benjaminadame/Downloads/lfw-deepfunneled/\" + tokens[2] + \"/\" + tokens[2] + \"_\" + \"{:04d}\".format(int(tokens[3]))+\".jpg\"\n",
    "    image1 = img.imread(url_name1)\n",
    "    image2 = img.imread(url_name2)\n",
    "    #reshape the images--- one image remains in one column\n",
    "    image1 = image1.reshape(250*250*3,)\n",
    "    image2 = image2.reshape(250*250*3,)\n",
    "    #input images into a feature vector in this case it is X\n",
    "    #0:187500 is accounting for the rows in the feature vector the same can be said for 187500:37500\n",
    "    # i is just the number of columns which represents the number of images that are being used\n",
    "    X_test[0:187500,500+i] = image1\n",
    "    X_test[187500:375000,500+i] = image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the labels for the testing set\n",
    "\n",
    "Y_test = np.zeros((1, 1000))\n",
    "for i in range(500):\n",
    "    Y_test[0, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the files \n",
    "np.save('X_test', X_test)\n",
    "np.save('Y_test', Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Machine Learning Stuff from this cell onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Files.....Loading takes 3 minutes.\n",
    "X_train = np.load('X_train.npy')\n",
    "Y_train = np.load('Y_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "Y_test = np.load('Y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------NETWORK ARCHITECTURE------------------------------------------\n",
    "#Setting up X_train and Y_train\n",
    "\n",
    "layer_dims = [X_train.shape[0],5,3,2,1]\n",
    "\n",
    "#sigmoid function \n",
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))\n",
    "\n",
    "#loss function\n",
    "def loss (A,Y):\n",
    "    l = Y * np.log(A) + (1-Y) * np.log(1-A)\n",
    "    return l\n",
    "\n",
    "#cost function\n",
    "def cost (m,A,Y):\n",
    "    c = (-1/m) * np.sum(loss(A,Y))\n",
    "    return c\n",
    "\n",
    "#initialize w and b, ld is short for layer_dims \n",
    "def initialize_parameters(ld):\n",
    "    W = []\n",
    "    b = []\n",
    "    \n",
    "    for i in range (0,4):\n",
    "        W.append(np.random.randn(ld[i+1],ld[i]))\n",
    "        b.append(np.random.randn(ld[i+1],1))  \n",
    "    return W,b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foward Propagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foward propagation \n",
    "def forward_prop(w,b,x,y,m):\n",
    "    \n",
    "    z = []\n",
    "    a = []\n",
    "    \n",
    "    \n",
    "    #propagate through each layer \n",
    "    #first layer \n",
    "    a.append(x)\n",
    "    z.append(np.dot(w[0],x)+b[0])\n",
    "    a.append(np.tanh(z[0]))\n",
    "    for i in range(1,3):\n",
    "        z.append(np.dot(w[i],a[i])+b[i])\n",
    "        a.append(np.tanh(z[i]))\n",
    "        \n",
    "    #last layer \n",
    "    #w.append(np.random.randn(ld[4],ld[3]))\n",
    "    #b.append(np.random.randn(ld[4],1))\n",
    "    z.append(np.dot(w[3],a[3])+b[3])\n",
    "    a.append(sigmoid(z[3]))\n",
    "    \n",
    "    #compute cost \n",
    "    J = cost(m,a[4],y)\n",
    "    return a,J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#back propagation \n",
    "def backward_prop(a,y,m):\n",
    "    #initialize the array structure \n",
    "    dz = [0,0,0,0]\n",
    "    dw = [0,0,0,0]\n",
    "    db = [0,0,0,0]\n",
    "    \n",
    "    #third layer initialization\n",
    "    dz[3] = a[4] - y\n",
    "    dw[3] = (1/m)*np.dot(dz[3],a[3].T)\n",
    "    db[3] = (1/m)*np.sum(dz[3],axis=1,keepdims=True)\n",
    "    for i in range (0,2):\n",
    "        dz[2-i] = np.dot(dw[2-i+1].T,dz[2-i+1])*(np.ones(a[2-i+1].shape)-np.power(a[2-i+1],2))\n",
    "        dw[2-i] = (1/m)*np.dot(dz[2-i],a[2-i].T)\n",
    "        db[2-i] = (1/m)*np.sum(dz[2-i],axis=1,keepdims=True)\n",
    "    return dw,db\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(w,b,dw,db,lr):\n",
    "    for i in range (0,4):\n",
    "        w[i] = w[i] - (lr * dw[i])\n",
    "        b[i] = b[i] - (lr * db[i])\n",
    "        \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main program "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748123992768185\n",
      "0.7318868477854586\n",
      "0.7265887320532277\n",
      "0.7245364902082629\n",
      "0.7234175860260902\n",
      "0.7225693187566116\n",
      "0.7218047525742017\n",
      "0.7210716196716782\n",
      "0.7203554797149418\n",
      "0.7196524412491161\n",
      "0.7189615179829665\n",
      "0.7182825027673686\n",
      "0.7176153841467957\n",
      "0.7169601903293904\n",
      "0.7163169496074918\n",
      "0.7156856814710394\n",
      "0.7150663952647797\n",
      "0.7144590904054137\n",
      "0.7138637567549686\n",
      "0.7132803749017258\n",
      "0.7127089163546341\n",
      "0.7121493436920017\n",
      "0.7116016106959249\n",
      "0.7110656624913281\n",
      "0.7105414356997292\n",
      "0.710028858612655\n",
      "0.7095278513866936\n",
      "0.7090383262605525\n",
      "0.7085601877935745\n",
      "0.7080933331246437\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 30\n",
    "learning_rate = 1\n",
    "m = 2200\n",
    "#initialize our parameters \n",
    "W,b = initialize_parameters(layer_dims)\n",
    "for i in range (num_iterations):\n",
    "    #propagate forward and back \n",
    "    A,J = forward_prop(W,b,X_train,Y_train,m)\n",
    "    dw,db = backward_prop(A,Y_train,m)\n",
    "    #apply the gradient descent \n",
    "    W,b = grad(W,b,dw,db,learning_rate)\n",
    "    print(J)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print cost-----> you need to have the cost decreasing every time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,w,b,m):\n",
    "    a = x\n",
    "    y_pred = np.zeros((1,m))\n",
    "    for i in range (0,3):\n",
    "        a = np.tanh(np.dot(w[i],a)+b[i])\n",
    "    a = sigmoid(np.dot(w[3], a)+b[3])\n",
    "    for i in range(0,m):    \n",
    "        if (a[0,i]<0.5):\n",
    "            y_pred[0,i] = 0\n",
    "        else:\n",
    "            y_pred[0,i] = 1\n",
    "        \n",
    "    return a, y_pred\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOW ACCURATE WILL THIS TEST BE........?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 93.7%\n"
     ]
    }
   ],
   "source": [
    "a, y_pred = predict(X_test,W,b,1000)\n",
    "diff = np.abs(y_pred-Y_test)\n",
    "negative_acc = np.mean(diff)\n",
    "acc = 1-negative_acc\n",
    "\n",
    "print(\"TEST ACCURACY: \" + str(acc*100)+\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
