{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55000 training examples!\n",
      "Cost after every iteration: 1.4877661459177571\n",
      "Cost after every iteration: 0.4246583133096015\n",
      "Cost after every iteration: 0.3658718533459059\n",
      "Cost after every iteration: 0.3379122286584784\n",
      "Cost after every iteration: 0.3210855757509947\n",
      "Cost after every iteration: 0.3091428671374855\n",
      "Cost after every iteration: 0.2998339337187128\n",
      "Cost after every iteration: 0.29238307756311344\n",
      "Cost after every iteration: 0.28620871255283326\n",
      "Cost after every iteration: 0.28073712478345375\n",
      "Cost after every iteration: 0.27564497446872593\n",
      "Cost after every iteration: 0.2707741677675977\n",
      "Cost after every iteration: 0.2660200707188655\n",
      "Cost after every iteration: 0.2613689243984846\n",
      "Cost after every iteration: 0.25686698301414346\n",
      "Cost after every iteration: 0.2525435677022971\n",
      "Cost after every iteration: 0.24841818325054965\n",
      "Cost after every iteration: 0.24449677605960007\n",
      "Cost after every iteration: 0.2407621019647409\n",
      "Cost after every iteration: 0.23720378785019242\n",
      "Cost after every iteration: 0.23381995242491976\n",
      "Cost after every iteration: 0.2306001970791662\n",
      "Cost after every iteration: 0.22753059723555943\n",
      "Cost after every iteration: 0.22459957952674328\n",
      "Cost after every iteration: 0.22179701711669544\n",
      "Cost after every iteration: 0.21911236732892825\n",
      "Cost after every iteration: 0.21653405251941954\n",
      "Cost after every iteration: 0.21405106978578142\n",
      "Cost after every iteration: 0.21165554005035808\n",
      "Cost after every iteration: 0.20934306656734836\n",
      "Cost after every iteration: 0.20711077190216923\n",
      "Cost after every iteration: 0.20495545616432775\n",
      "Cost after every iteration: 0.20287325943964613\n",
      "Cost after every iteration: 0.2008601571522323\n",
      "Cost after every iteration: 0.19891224834075732\n",
      "Cost after every iteration: 0.19702568263457962\n",
      "Cost after every iteration: 0.19519656153909545\n",
      "Cost after every iteration: 0.1934210366051755\n",
      "Cost after every iteration: 0.19169555550428047\n",
      "Cost after every iteration: 0.1900170872539155\n",
      "Cost after every iteration: 0.18838319245716112\n",
      "Cost after every iteration: 0.18679192533712197\n",
      "Cost after every iteration: 0.18524166714122295\n",
      "Cost after every iteration: 0.18373098729815346\n",
      "Cost after every iteration: 0.18225854426804133\n",
      "Cost after every iteration: 0.18082299553619444\n",
      "Cost after every iteration: 0.17942292546581157\n",
      "Cost after every iteration: 0.17805684487311732\n",
      "Cost after every iteration: 0.17672328112189747\n",
      "Cost after every iteration: 0.17542089241298586\n",
      "Cost after every iteration: 0.17414851645647367\n",
      "Cost after every iteration: 0.1729051297641591\n",
      "Cost after every iteration: 0.17168976467159555\n",
      "Cost after every iteration: 0.17050144235542952\n",
      "Cost after every iteration: 0.16933914863039687\n",
      "Cost after every iteration: 0.168201845652964\n",
      "Cost after every iteration: 0.16708849682677107\n",
      "Cost after every iteration: 0.16599808635920232\n",
      "Cost after every iteration: 0.16492963000174563\n",
      "Cost after every iteration: 0.16388218700508286\n",
      "Cost after every iteration: 0.16285488482495883\n",
      "Cost after every iteration: 0.16184695335862714\n",
      "Cost after every iteration: 0.1608577478225464\n",
      "Cost after every iteration: 0.15988674047815338\n",
      "Cost after every iteration: 0.15893348210768157\n",
      "Cost after every iteration: 0.15799755337603746\n",
      "Cost after every iteration: 0.15707852722796783\n",
      "Cost after every iteration: 0.15617594882891836\n",
      "Cost after every iteration: 0.1552893246207467\n",
      "Cost after every iteration: 0.15441811042758047\n",
      "Cost after every iteration: 0.1535617003842742\n",
      "Cost after every iteration: 0.15271942888056786\n",
      "Cost after every iteration: 0.15189059266068528\n",
      "Cost after every iteration: 0.15107448491114092\n",
      "Cost after every iteration: 0.15027042503260396\n",
      "Cost after every iteration: 0.1494777738491683\n",
      "Cost after every iteration: 0.14869593549697768\n",
      "Cost after every iteration: 0.14792435330033019\n",
      "Cost after every iteration: 0.14716250616616644\n",
      "Cost after every iteration: 0.14640990959679856\n",
      "Cost after every iteration: 0.14566612333275847\n",
      "Cost after every iteration: 0.14493076391696388\n",
      "Cost after every iteration: 0.1442035161866574\n",
      "Cost after every iteration: 0.1434841370499058\n",
      "Cost after every iteration: 0.14277244884888396\n",
      "Cost after every iteration: 0.14206832444694992\n",
      "Cost after every iteration: 0.1413716684159478\n",
      "Cost after every iteration: 0.14068239869019505\n",
      "Cost after every iteration: 0.14000043279539906\n",
      "Cost after every iteration: 0.13932568218789765\n",
      "Cost after every iteration: 0.1386580558942468\n",
      "Cost after every iteration: 0.1379974708587962\n",
      "Cost after every iteration: 0.13734386357164946\n",
      "Cost after every iteration: 0.13669719750045245\n",
      "Cost after every iteration: 0.13605746331621435\n",
      "Cost after every iteration: 0.13542467224345417\n",
      "Cost after every iteration: 0.1347988454453161\n",
      "Cost after every iteration: 0.13418000327919113\n",
      "Cost after every iteration: 0.13356815746507353\n",
      "Cost after every iteration: 0.13296330729418404\n",
      "96.33% Test Accuracy\n"
     ]
    }
   ],
   "source": [
    "# Get Inputs and Labels in proper format\n",
    "num_iterations = 100\n",
    "learning_rate = .1\n",
    "X=mnist.train.images\n",
    "Y=np.reshape(mnist.train.labels[:,0], (mnist.train.labels.shape[0], 1)).T\n",
    "X_TEST = mnist.test.images\n",
    "Y_TEST = np.reshape(mnist.test.labels[:,0], (mnist.test.labels.shape[0], 1)).T\n",
    "\n",
    "#Let X inputs be 1 column \n",
    "X_col = X.T\n",
    "X_TEST_col = X_TEST.T\n",
    "\n",
    "#training set size \n",
    "m = Y.shape[1]\n",
    "print(\"There are \"+str(m)+\" training examples!\")\n",
    "\n",
    "#defining the network structure \n",
    "n_x = X_col.shape[0]\n",
    "n_hidden_layer_size = 4\n",
    "n_y = Y.shape[0]\n",
    "\n",
    "#sigmoid function \n",
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))\n",
    "\n",
    "#loss function\n",
    "def loss (A,Y):\n",
    "    l = Y * np.log(A) + (1-Y) * np.log(1-A)\n",
    "    return l\n",
    "\n",
    "#cost function\n",
    "def cost (m,A,Y):\n",
    "    c = (-1/m) * np.sum(loss(A,Y))\n",
    "    return c\n",
    "\n",
    "#initialize layers\n",
    "def initialize_parameters(x,hidden,y):\n",
    "    W1 = np.random.randn(hidden,x)\n",
    "    b1 = np.zeros((hidden,1))\n",
    "    W2 = np.random.randn(y,hidden)\n",
    "    b2 = np.zeros((y,1))\n",
    "    return W1,b1,W2,b2\n",
    "\n",
    "#predict function \n",
    "def predict(x,w1,b1,w2,b2):\n",
    "    Z1 = np.dot(w1,x)+b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(w2,A1)+b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    Y_prediction = np.zeros((1,x.shape[1]))\n",
    "    for i in range (0,x.shape[1]):\n",
    "        if A2[0,i] < 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "    return Y_prediction\n",
    "\n",
    "#initialize params\n",
    "W1,b1,W2,b2 = initialize_parameters(n_x,n_hidden_layer_size,n_y)\n",
    "\n",
    "for i in range (0,num_iterations):\n",
    "    #foward propagation\n",
    "    Z1 = np.dot(W1,X_col)+b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2,A1)+b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    J = cost(m,A2,Y)\n",
    "    \n",
    "    #back propagation\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * np.dot(dZ2,A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims = True)\n",
    "    dZ1 = np.dot(W2.T,dZ2) * np.power((1-A1),2)\n",
    "    dW1 = (1/m) * np.dot(dZ1,X_col.T)\n",
    "    db1 = (1/m) * np.sum(dZ1,axis=1,keepdims=True)\n",
    "    \n",
    "    #update with gradient descent\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    \n",
    "    #print cost \n",
    "    print(\"Cost after every iteration: \"+ str(J))\n",
    "    \n",
    "    #shapes of our matrix \n",
    "    #print(Z2.shape,W2.shape,b2.shape,Z1.shape,W1.shape,b1.shape)\n",
    "    #print(dZ2.shape, dW2.shape, db2.shape, dZ1.shape, dW1.shape, db1.shape)\n",
    "\n",
    "#make prediction\n",
    "Y_PREDICT = predict(X_TEST_col,W1,b1,W2,b2)\n",
    "Y_TRAIN_PREDICT = predict(X_col,W1,b1,W2,b2)\n",
    "\n",
    "#Compute Accuracy of Model\n",
    "number_correct = 0\n",
    "for i in range (0,Y_PREDICT.shape[1]):\n",
    "    if Y_PREDICT[0,i] == Y_TEST[0,i]:\n",
    "        number_correct+=1 \n",
    "    else:\n",
    "        pass\n",
    "#print Training accuracy \n",
    "print(str((number_correct/10000) * 100)+\"% Test Accuracy\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
