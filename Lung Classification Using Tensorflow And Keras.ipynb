{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this assignment we will be creating a multi-layer network that will be able to learn what a healthy lung looks like vs a non healthy lung that has Pnuemonia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- first step: PARSE THE DATA VERYYYYY TIME CONSUMMING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#from resizeimage import resizeimage\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_set_url = \"/Users/benjaminadame/Downloads/chest_xray\"\n",
    "data_set_url = \"/home/gautam/.keras/datasets/chest_xray\"\n",
    "\n",
    "normal_url_train = data_set_url + \"/train/NORMAL/\"\n",
    "pneumonia_url_train = data_set_url + \"/train/PNEUMONIA/\"\n",
    "normal_url_test = data_set_url + \"/test/NORMAL/\"\n",
    "pneumonia_url_test = data_set_url + \"/test/PNEUMONIA/\"\n",
    "input_size = 2500\n",
    "\n",
    "#initializing training and testing matrices \n",
    "def initialize_test_train(n,p):\n",
    "    #size of the image that we want\n",
    "    size = [50,50]\n",
    "    i = 0\n",
    "    #Open trainng directorys\n",
    "    n_d = listdir(n)\n",
    "    p_d = listdir(p)\n",
    "        \n",
    "    #nnp: number of normal pictures in training data\n",
    "    nnp = len(n_d)\n",
    "    #npp: number of pneumonia pictures in training data\n",
    "    npp = len(p_d)\n",
    "    #row is speaking of image size which is 50*50*3\n",
    "    x = np.zeros((nnp+npp, input_size))\n",
    "    #row is speaking about label 1 label for each\n",
    "    y = np.zeros((nnp+npp,1))\n",
    "    #Process NORMAL lung files for training and testing set \n",
    "    for file in n_d:\n",
    "        #print(file)    \n",
    "        #Resizing images\n",
    "        with open(n + file, 'r+b') as f:\n",
    "            with Image.open(f) as image:\n",
    "                cover = image.resize((50,50))\n",
    "                cover = np.array(cover)\n",
    "                if cover.shape == (50, 50):\n",
    "                    cover = cover.reshape(1,input_size)\n",
    "                    x[i,:] = cover\n",
    "                    y[i,0] = 0\n",
    "                    i += 1\n",
    "            \n",
    "    #Process PNEUMONIA lung files for training and testing set \n",
    "    for file in p_d:\n",
    "        #print(file)\n",
    "        #Resize images\n",
    "        with open(p + file, 'r+b') as f:\n",
    "            with Image.open(f) as image:\n",
    "                cover = image.resize((50,50))\n",
    "                cover = np.array(cover)\n",
    "                if cover.shape == (50,50):\n",
    "                    cover = cover.reshape(1,input_size)\n",
    "                    x[i, :] = cover\n",
    "                    y[i,0] = 1\n",
    "                    i += 1\n",
    "                    \n",
    "    return x[0:i,:], y[0:i,:]\n",
    "    \n",
    "#call x and y to initialize matrices\n",
    "X_train, Y_train = initialize_test_train(normal_url_train,pneumonia_url_train)\n",
    "X_test, Y_test = initialize_test_train(normal_url_test,pneumonia_url_test)\n",
    "\n",
    "#print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4949, 2500) (624, 2500) (4949, 1) (624, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow Datasets\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "Y_train = tf.convert_to_tensor(Y_train, dtype=tf.float32)\n",
    "Y_test = tf.convert_to_tensor(Y_test, dtype=tf.float32)\n",
    "\n",
    "#create train dataset\n",
    "train_dataset = tf.data.Dataset.from_tensors((X_train,Y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensors((X_test,Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the Network Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model architechture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(5,activation = \"relu\",input_shape = (2500,)),\n",
    "    tf.keras.layers.Dense(3,activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(2,activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(1,activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the foward propagation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(model,x,y):\n",
    "    a = model(x)\n",
    "    loss = tf.losses.sigmoid_cross_entropy(y,a)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Gradienr Descent //optimizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .1\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Time!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.6049038171768188\n",
      "cost: 0.6044018268585205\n",
      "cost: 0.6038941144943237\n",
      "cost: 0.6034396290779114\n",
      "cost: 0.6029759049415588\n",
      "cost: 0.6025326251983643\n",
      "cost: 0.6020899415016174\n",
      "cost: 0.6016761064529419\n",
      "cost: 0.6012721657752991\n",
      "cost: 0.6009052395820618\n",
      "cost: 0.6005217432975769\n",
      "cost: 0.6001666188240051\n",
      "cost: 0.5998056530952454\n",
      "cost: 0.5994661450386047\n",
      "cost: 0.599143385887146\n",
      "cost: 0.5988265872001648\n",
      "cost: 0.5985205173492432\n",
      "cost: 0.5982186198234558\n",
      "cost: 0.5979374051094055\n",
      "cost: 0.5976781249046326\n",
      "cost: 0.597405731678009\n",
      "cost: 0.5971387028694153\n",
      "cost: 0.5968919992446899\n",
      "cost: 0.5966417789459229\n",
      "cost: 0.5964164733886719\n",
      "cost: 0.5962035655975342\n",
      "cost: 0.5959715247154236\n",
      "cost: 0.595751941204071\n",
      "cost: 0.5955595374107361\n",
      "cost: 0.5953627228736877\n",
      "cost: 0.5951564311981201\n",
      "cost: 0.5949842929840088\n",
      "cost: 0.5948003530502319\n",
      "cost: 0.5946063995361328\n",
      "cost: 0.5944474339485168\n",
      "cost: 0.5942801833152771\n",
      "cost: 0.5941110253334045\n",
      "cost: 0.59395831823349\n",
      "cost: 0.5938080549240112\n",
      "cost: 0.593654990196228\n",
      "cost: 0.5935237407684326\n",
      "cost: 0.5933902263641357\n",
      "cost: 0.5932480096817017\n",
      "cost: 0.5931090116500854\n",
      "cost: 0.5929869413375854\n",
      "cost: 0.5928676128387451\n",
      "cost: 0.5927417278289795\n",
      "cost: 0.5926164388656616\n",
      "cost: 0.5925108194351196\n",
      "cost: 0.5924057960510254\n",
      "cost: 0.5922970771789551\n",
      "cost: 0.592178225517273\n",
      "cost: 0.59209144115448\n",
      "cost: 0.5919696092605591\n",
      "cost: 0.5918803215026855\n",
      "cost: 0.5917819738388062\n",
      "cost: 0.5916876196861267\n",
      "cost: 0.591616153717041\n",
      "cost: 0.5915094614028931\n",
      "cost: 0.5914260745048523\n",
      "cost: 0.5913476347923279\n",
      "cost: 0.5912622213363647\n",
      "cost: 0.5911791324615479\n",
      "cost: 0.5911113023757935\n",
      "cost: 0.591027557849884\n",
      "cost: 0.5909607410430908\n",
      "cost: 0.5908951759338379\n",
      "cost: 0.5908250212669373\n",
      "cost: 0.5907520651817322\n",
      "cost: 0.5906721949577332\n",
      "cost: 0.5905992984771729\n",
      "cost: 0.5905474424362183\n",
      "cost: 0.5904941558837891\n",
      "cost: 0.5904154777526855\n",
      "cost: 0.5903541445732117\n",
      "cost: 0.5902969837188721\n",
      "cost: 0.590235710144043\n",
      "cost: 0.590178370475769\n",
      "cost: 0.5901378393173218\n",
      "cost: 0.5900741815567017\n",
      "cost: 0.5900377631187439\n",
      "cost: 0.5899649262428284\n",
      "cost: 0.5899286866188049\n",
      "cost: 0.5898795127868652\n",
      "cost: 0.5898085832595825\n",
      "cost: 0.5897607803344727\n",
      "cost: 0.58971107006073\n",
      "cost: 0.5896874666213989\n",
      "cost: 0.5896419882774353\n",
      "cost: 0.5895835757255554\n",
      "cost: 0.5895568132400513\n",
      "cost: 0.5895029902458191\n",
      "cost: 0.5894731879234314\n",
      "cost: 0.5894107222557068\n",
      "cost: 0.5893852114677429\n",
      "cost: 0.5893473029136658\n",
      "cost: 0.5893161296844482\n",
      "cost: 0.5892514586448669\n",
      "cost: 0.5892161726951599\n",
      "cost: 0.589177131652832\n"
     ]
    }
   ],
   "source": [
    "m = 5232\n",
    "epochs = 1000\n",
    "\n",
    "#loop it\n",
    "for epoch in range(epochs):\n",
    "    loss_avg = tfe.metrics.Mean()\n",
    "    \n",
    "    for x,y in train_dataset:\n",
    "        with tf.GradientTape(persistent = True) as tape:\n",
    "            loss = forward_prop(model,x,y)\n",
    "            #grad: gives you dw,db while model.vars gives you w and b\n",
    "        grad = tape.gradient(loss,model.variables)\n",
    "        loss_avg(loss)\n",
    "        #update with grad descent \n",
    "        optimizer.apply_gradients(zip(grad,model.variables))\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"cost: {}\".format(loss_avg.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
